{"type": "single_question", "input": {"type": "JD", "content": "JD: Frontend React Advanced Engineer\n- Responsibilities: Build and operate systems in Frontend React Advanced.\n- Tech stack: React, Redux Toolkit, Next.js 14, React Query, Zustand."}, "meta": {"domain": "Frontend React Advanced", "frameworks": ["React", "Redux Toolkit", "Next.js 14", "React Query", "Zustand", "Recoil", "TypeScript"], "category": "Messaging", "level": "mid", "difficulty": "medium"}, "question": "What would your approach be to implementing optimization at scale?"}
{"type": "conversation", "input": {"type": "interview_session", "jd": "JD: DevSecOps Engineer\n- Tech stack: GitHub Actions, Snyk, OPA, Vault, Cosign", "position": "DevSecOps", "level": "mid"}, "conversation": [{"turn": 1, "question": "What's your understanding of GitOps with ArgoCD sync policies in the context of GitHub Actions?", "answer": "Sure, I can explain that. The approach to GitOps with ArgoCD sync policies is typically SBOM generation with Syft and attestation. We implement implementing caching at multiple layers to achieve cuts infrastructure costs by 40%. It's worked well for similar use cases.", "concept": "GitOps with ArgoCD sync policies"}, {"turn": 2, "question": "Let's shift to GitHub Actions OIDC for AWS. What other technologies would you combine with SBOM generation with Syft and attestation?", "answer": "Yes, I've worked with this before. GitHub Actions OIDC for AWS requires GitHub Actions OIDC with AWS assume-role setup. The applying horizontal scaling with load balancing pattern works well for allows faster incident recovery. This pattern has been reliable in my projects.", "concept": "GitHub Actions OIDC for AWS"}, {"turn": 3, "question": "If you had to rebuild GitHub Actions OIDC with AWS assume-role from scratch, what would you do differently?", "answer": "Right, so the way I approach this is GitHub Actions OIDC for AWS requires Trivy scanning with severity thresholds setup. The implementing circuit breakers for fault tolerance pattern works well for catches issues before they reach production. That's how I've seen it done in production.", "concept": "GitHub Actions OIDC for AWS"}, {"turn": 4, "question": "Let's shift to GitHub Actions OIDC for AWS. That's interesting about GitHub Actions OIDC for AWS. What's been your experience with it?", "answer": "That's a good question. In my case, I handle GitHub Actions OIDC for AWS by using SBOM generation with Syft and attestation with implementing rate limiting per user/API key. It helps with prevents data loss during failures pretty reliably. That's the standard approach in the team.", "concept": "GitHub Actions OIDC for AWS"}], "meta": {"domain": "DevSecOps", "frameworks": ["GitHub Actions", "Snyk", "OPA", "Vault", "Cosign", "Trivy", "Falco"], "level": "mid", "num_turns": 4, "candidate_quality": "good", "total_questions": 4}}
{"type": "single_question", "input": {"type": "JD", "content": "JD: Testing Advanced\n- Responsibilities: Design testing advanced architectures; security; networking; data & serverless; CI/CD.\n- Requirements: Selenium, Cypress, Jest, JUnit.\n- Tech stack: Selenium, Cypress, Jest, JUnit, PyTest, k6, JMeter, Pact, Testcontainers."}, "meta": {"domain": "Testing Advanced", "frameworks": ["Selenium", "Cypress", "Jest", "JUnit", "PyTest", "k6", "JMeter", "Pact", "Testcontainers"], "category": "Simulation", "level": "junior", "difficulty": "easy"}, "question": "Can you explain how parallel test execution with sharding works in Testing Advanced?"}
{"type": "single_question", "input": {"type": "CV", "content": "CV: Candidate mid with 3–5 years of experience in Cloud Azure/GCP. Main skills: Azure, GCP, AKS, GKE, Cloud Run. Strengths: Testing, Reliability."}, "meta": {"domain": "Cloud Azure/GCP", "frameworks": ["Azure", "GCP", "AKS", "GKE", "Cloud Run", "BigQuery", "Pub/Sub", "Key Vault", "Secret Manager"], "category": "Experimentation", "level": "mid", "difficulty": "medium"}, "question": "How would you optimize optimization in a production environment in an enterprise environment?"}
{"type": "single_question", "input": {"type": "CV", "content": "CV: Candidate junior with 1–3 years of experience in Energy Systems / SCADA. Main skills: SCADA, IEC 61850, DNP3, OPC UA. Strengths: Problem-solving, Teamwork."}, "meta": {"domain": "Energy Systems / SCADA", "frameworks": ["SCADA", "IEC 61850", "DNP3", "OPC UA"], "category": "Retrieval", "level": "junior", "difficulty": "medium"}, "question": "How would you implement system design in a SCADA application with high availability requirements?"}
{"type": "single_question", "input": {"type": "CV", "content": "CV: Candidate senior with 4–8 years of experience in Supply Chain/Logistics. Main skills: SAP, Oracle, Manhattan, AWS IoT, Kafka. Strengths: Reliability, Performance, Scalability."}, "meta": {"domain": "Supply Chain/Logistics", "frameworks": ["SAP", "Oracle", "Manhattan", "AWS IoT", "Kafka", "GraphDB"], "category": "UX", "level": "senior", "difficulty": "medium"}, "question": "What would your approach be to handle architecture at enterprise level?"}
{"type": "single_question", "input": {"type": "CV", "content": "CV: Candidate junior with 1–3 years of experience in Go Backend. Main skills: Go, Gin, Echo, gRPC, PostgreSQL. Strengths: Security, Problem-solving, Architecture."}, "meta": {"domain": "Go Backend", "frameworks": ["Go", "Gin", "Echo", "gRPC", "PostgreSQL", "Redis", "Docker"], "category": "Testing", "level": "junior", "difficulty": "easy"}, "question": "If you needed to test a pipeline, what approach would you take?"}
{"type": "single_question", "input": {"type": "JD", "content": "JD: Frontend Vue Advanced Engineer\n- Responsibilities: Build and operate systems in Frontend Vue Advanced.\n- Tech stack: Vue 3, Pinia, Nuxt 3, VueUse, Vitest."}, "meta": {"domain": "Frontend Vue Advanced", "frameworks": ["Vue 3", "Pinia", "Nuxt 3", "VueUse", "Vitest", "TypeScript"], "category": "Retrieval", "level": "junior", "difficulty": "easy"}, "question": "What approach would you use to handle architecture in your team?"}
{"type": "single_question", "input": {"type": "JD", "content": "Auto-generated for Cloud AWS"}, "meta": {"domain": "Cloud AWS", "frameworks": ["AWS", "EC2", "Lambda", "ECS", "S3", "RDS", "DynamoDB", "CloudFormation"], "category": "Metrics", "level": "senior", "difficulty": "hard"}, "question": "What would your approach be to tackle EventBridge for event-driven architecture at enterprise level in a distributed system?"}
{"type": "conversation", "input": {"type": "interview_session", "jd": "JD: Cloud Azure/GCP Engineer\n- Tech stack: Azure, GCP, AKS, GKE, Cloud Run", "position": "Cloud Azure/GCP", "level": "intern"}, "conversation": [{"turn": 1, "question": "Let's start with system design. How do you approach this in Azure?", "answer": "Yes, I've worked with this before. For system design, I would use standard approaches - the basic setup includes implementing proper security headers and CORS which provides enables zero-downtime deployments. That's how I've seen it done in production.", "concept": "system design"}, {"turn": 2, "question": "What edge cases have you seen with CORS?", "answer": "Right, so the way I approach this is The way I implement system design is through standard approaches, using using database indexes strategically to get enables zero-downtime deployments. That's how I've seen it done in production.", "concept": "system design"}, {"turn": 3, "question": "I'm curious about system design. What made you choose that approach?", "answer": "That's a good question. In my case, For system design, we use standard approaches combined with using idempotency keys for safe retries, which ensures handles 10x more concurrent requests. That's the standard approach in the team.", "concept": "system design"}, {"turn": 4, "question": "How do you train new team members on That?", "answer": "I've used this in projects where With system design, you configure standard approaches and then apply applying the saga pattern for distributed transactions. This gives you enables better capacity planning. That's how I've seen it done in production.", "concept": "system design"}], "meta": {"domain": "Cloud Azure/GCP", "frameworks": ["Azure", "GCP", "AKS", "GKE", "Cloud Run", "BigQuery", "Pub/Sub", "Key Vault", "Secret Manager"], "level": "intern", "num_turns": 4, "candidate_quality": "good", "total_questions": 4}}
